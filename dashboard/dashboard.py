import os
import duckdb
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import folium
from streamlit_folium import st_folium
import requests

from dotenv import dotenv_values, load_dotenv
from pathlib import Path

# Configuration de la page
st.set_page_config(
    page_title="CHU - Tableau de Bord Sant√©",
    page_icon="üè•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Load environment variables from .env file
load_dotenv('/app/.env')
# Or simply (since /app is the working directory)
load_dotenv()

# Configuration de la connexion MotherDuck
MOTHERDUCK_TOKEN = os.getenv("MOTHERDUCK_TOKEN", "")
# Mapping code postal ‚Üí r√©gion (bas√© sur les 2 premiers chiffres)
CODE_POSTAL_TO_REGION = {
    # √éle-de-France
    '75': '√éle-de-France', '77': '√éle-de-France', '78': '√éle-de-France', '91': '√éle-de-France', '92': '√éle-de-France', '93': '√éle-de-France', '94': '√éle-de-France', '95': '√éle-de-France',
    # Auvergne-Rh√¥ne-Alpes
    '01': 'Auvergne-Rh√¥ne-Alpes', '03': 'Auvergne-Rh√¥ne-Alpes', '07': 'Auvergne-Rh√¥ne-Alpes', '15': 'Auvergne-Rh√¥ne-Alpes', '26': 'Auvergne-Rh√¥ne-Alpes', '38': 'Auvergne-Rh√¥ne-Alpes', '42': 'Auvergne-Rh√¥ne-Alpes', '43': 'Auvergne-Rh√¥ne-Alpes', '63': 'Auvergne-Rh√¥ne-Alpes', '69': 'Auvergne-Rh√¥ne-Alpes', '73': 'Auvergne-Rh√¥ne-Alpes', '74': 'Auvergne-Rh√¥ne-Alpes',
    # Occitanie
    '09': 'Occitanie', '11': 'Occitanie', '12': 'Occitanie', '30': 'Occitanie', '31': 'Occitanie', '32': 'Occitanie', '34': 'Occitanie', '46': 'Occitanie', '48': 'Occitanie', '65': 'Occitanie', '66': 'Occitanie', '81': 'Occitanie', '82': 'Occitanie',
    # Nouvelle-Aquitaine
    '16': 'Nouvelle-Aquitaine', '17': 'Nouvelle-Aquitaine', '19': 'Nouvelle-Aquitaine', '23': 'Nouvelle-Aquitaine', '24': 'Nouvelle-Aquitaine', '33': 'Nouvelle-Aquitaine', '40': 'Nouvelle-Aquitaine', '47': 'Nouvelle-Aquitaine', '64': 'Nouvelle-Aquitaine', '79': 'Nouvelle-Aquitaine', '86': 'Nouvelle-Aquitaine', '87': 'Nouvelle-Aquitaine',
    # Hauts-de-France
    '02': 'Hauts-de-France', '59': 'Hauts-de-France', '60': 'Hauts-de-France', '62': 'Hauts-de-France', '80': 'Hauts-de-France',
    # Provence-Alpes-C√¥te d'Azur
    '04': 'Provence-Alpes-C√¥te d\'Azur', '05': 'Provence-Alpes-C√¥te d\'Azur', '06': 'Provence-Alpes-C√¥te d\'Azur', '13': 'Provence-Alpes-C√¥te d\'Azur', '83': 'Provence-Alpes-C√¥te d\'Azur', '84': 'Provence-Alpes-C√¥te d\'Azur',
    # Grand Est
    '08': 'Grand Est', '10': 'Grand Est', '51': 'Grand Est', '52': 'Grand Est', '54': 'Grand Est', '55': 'Grand Est', '57': 'Grand Est', '67': 'Grand Est', '68': 'Grand Est', '88': 'Grand Est',
    # Normandie
    '14': 'Normandie', '27': 'Normandie', '50': 'Normandie', '61': 'Normandie', '76': 'Normandie',
    # Pays de la Loire
    '44': 'Pays de la Loire', '49': 'Pays de la Loire', '53': 'Pays de la Loire', '72': 'Pays de la Loire', '85': 'Pays de la Loire',
    # Bretagne
    '22': 'Bretagne', '29': 'Bretagne', '35': 'Bretagne', '56': 'Bretagne',
    # Centre-Val de Loire
    '18': 'Centre-Val de Loire', '28': 'Centre-Val de Loire', '36': 'Centre-Val de Loire', '37': 'Centre-Val de Loire', '41': 'Centre-Val de Loire', '45': 'Centre-Val de Loire',
    # Bourgogne-Franche-Comt√©
    '21': 'Bourgogne-Franche-Comt√©', '25': 'Bourgogne-Franche-Comt√©', '39': 'Bourgogne-Franche-Comt√©', '58': 'Bourgogne-Franche-Comt√©', '70': 'Bourgogne-Franche-Comt√©', '71': 'Bourgogne-Franche-Comt√©', '89': 'Bourgogne-Franche-Comt√©', '90': 'Bourgogne-Franche-Comt√©',
    # Corse
    '20': 'Corse',  # Note: 20 est aussi Ajaccio, mais on consid√®re 20 comme Corse principalement
}

def get_region_from_code_postal(code):
    """Extrait la r√©gion depuis un code postal"""
    if code is None or code == "":
        return None
    # Prendre les 2 premiers chiffres du code
    dept = str(code)[:2]
    return CODE_POSTAL_TO_REGION.get(dept, None)

def get_connection():
    """Connexion √† MotherDuck"""
    try:
        conn = duckdb.connect(f"md:?motherduck_token={MOTHERDUCK_TOKEN}")
        # Attacher le lakehouse si n√©cessaire
        try:
            conn.execute("ATTACH 'md:lakehouse'")
        except:
            pass  # D√©j√† attach√©
        return conn
    except Exception as e:
        st.error(f"Erreur de connexion: {e}")
        return None

@st.cache_data
def execute_query(query, params=None):
    """Ex√©cuter une requ√™te avec cache"""
    conn = get_connection()
    if conn is None:
        return None
    
    try:
        if params:
            result = conn.execute(query, params)
        else:
            result = conn.execute(query)
        
        data = result.fetchall()
        columns = [desc[0] for desc in result.description]
        df = pd.DataFrame(data, columns=columns)
        
        # Fermer la connexion
        conn.close()
        
        return df
    except Exception as e:
        st.error(f"Erreur requ√™te: {e}")
        if conn:
            conn.close()
        return None

@st.cache_data
def get_regions_geojson():
    """R√©cup√®re le GeoJSON des r√©gions fran√ßaises"""
    try:
        # URL du GeoJSON des r√©gions fran√ßaises (simplifi√©)
        # Utilisation d'une source publique
        url = "https://raw.githubusercontent.com/gregoiredavid/france-geojson/master/regions.geojson"
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.warning(f"Impossible de charger le GeoJSON des r√©gions: {e}")
        return None

def map_region_name_to_geojson(region_name):
    """Mappe le nom de r√©gion vers le nom dans le GeoJSON"""
    # Mapping des noms de r√©gions vers ceux dans le GeoJSON
    mapping = {
        '√éle-de-France': '√éle-de-France',
        'Auvergne-Rh√¥ne-Alpes': 'Auvergne-Rh√¥ne-Alpes',
        'Occitanie': 'Occitanie',
        'Nouvelle-Aquitaine': 'Nouvelle-Aquitaine',
        'Hauts-de-France': 'Hauts-de-France',
        'Provence-Alpes-C√¥te d\'Azur': 'Provence-Alpes-C√¥te d\'Azur',
        'Grand Est': 'Grand Est',
        'Normandie': 'Normandie',
        'Pays de la Loire': 'Pays de la Loire',
        'Bretagne': 'Bretagne',
        'Centre-Val de Loire': 'Centre-Val de Loire',
        'Bourgogne-Franche-Comt√©': 'Bourgogne-Franche-Comt√©',
        'Corse': 'Corse'
    }
    return mapping.get(region_name, region_name)

def main():
    # En-t√™te principal
    st.title("üè• CHU - Tableau de Bord Sant√©")
    st.markdown("**Cloud Healthcare Unit - Syst√®me D√©cisionnel Big Data**")
    
    # Sidebar pour la navigation
    st.sidebar.title("üìä Navigation")
    analysis_type = st.sidebar.selectbox(
        "Type d'analyse",
        [
            "üìà Vue d'ensemble",
            "üè• Hospitalisations", 
            "üë• Consultations",
            "üïäÔ∏è D√©c√®s",
            "üòä Satisfaction Globale"
        ]
    )
    
    # Filtres communs
    st.sidebar.markdown("---")
    st.sidebar.subheader("üîç Filtres")
    
    # D√©terminer quels filtres afficher selon l'analyse
    if analysis_type == "üïäÔ∏è D√©c√®s":
        # D√©c√®s forc√© √† 2019, pas de filtre de date ni r√©gion
        st.sidebar.info("üìÖ **D√©c√®s** : Analyse limit√©e √† l'ann√©e 2019\n‚ùå Pas de filtres date/r√©gion")
        start_date = datetime(2019, 1, 1).date()
        end_date = datetime(2019, 12, 31).date()
        region = "Toutes"
    elif analysis_type == "üòä Satisfaction Globale":
        # Satisfaction pas de localisation possible
        st.sidebar.info("üìÖ **Satisfaction** : Donn√©es 2017 globales\n‚ùå Pas de filtres date/r√©gion")
        start_date = datetime(2017, 1, 1).date()
        end_date = datetime(2017, 12, 31).date()
        region = "Toutes"
    else:
        # Pour les autres analyses, afficher les filtres
        # P√©riode
        col1, col2 = st.sidebar.columns(2)
        with col1:
            start_date = st.date_input("Date d√©but", value=datetime(2019, 1, 1))
        with col2:
            end_date = st.date_input("Date fin", value=datetime(2020, 12, 31))
        
        # R√©gion - Filtre bas√© sur code_lieu (code postal)
        region = st.sidebar.selectbox(
            "R√©gion",
            [
                "Toutes",
                "Auvergne-Rh√¥ne-Alpes",
                "Bourgogne-Franche-Comt√©",
                "Bretagne",
                "Centre-Val de Loire",
                "Corse",
                "Grand Est",
                "Hauts-de-France",
                "√éle-de-France",
                "Normandie",
                "Nouvelle-Aquitaine",
                "Occitanie",
                "Pays de la Loire",
                "Provence-Alpes-C√¥te d'Azur"
            ]
        )
    
    # Contenu principal selon l'analyse s√©lectionn√©e
    if analysis_type == "üìà Vue d'ensemble":
        show_overview(start_date, end_date, region)
    elif analysis_type == "üè• Hospitalisations":
        show_hospitalizations(start_date, end_date, region)
    elif analysis_type == "üë• Consultations":
        show_consultations(start_date, end_date, region)
    elif analysis_type == "üïäÔ∏è D√©c√®s":
        show_deaths(start_date, end_date, region)
    elif analysis_type == "üòä Satisfaction Globale":
        show_satisfaction(start_date, end_date, region)

def show_overview(start_date, end_date, region):
    """Vue d'ensemble du syst√®me"""
    st.header("üìà Vue d'ensemble du syst√®me")
    
    # M√©triques principales avec vraies donn√©es
    col1, col2, col3, col4 = st.columns(4)
    
    # R√©cup√©rer les vraies donn√©es depuis l'entrep√¥t OLAP
    try:
        # Total hospitalisations depuis la table de faits
        # Filtre par r√©gion via code_lieu (code postal)
        if region == "Toutes":
            region_filter = ""
            region_param = []
        else:
            # Trouver les d√©partements de la r√©gion s√©lectionn√©e
            depts = [dept for dept, reg in CODE_POSTAL_TO_REGION.items() if reg == region]
            if depts:
                # Cr√©er une condition SQL pour v√©rifier les 2 premiers chiffres du code_lieu
                conditions = " OR ".join([f"SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) = '{dept}'" for dept in depts])
                region_filter = f"AND ({conditions})"
            else:
                region_filter = ""
            region_param = []
        
        df_hosp = execute_query(f"""
            SELECT SUM(f.nombre_hospitalisation) as total 
            FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
            JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
            {f"LEFT JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu" if region_filter else ""}
            WHERE f.type_evenement = 'HOSPITALISATION'
            AND t.date_complete >= ? AND t.date_complete <= ?
            {region_filter}
        """, [start_date, end_date] + region_param)
        total_hosp = df_hosp['total'].iloc[0] if df_hosp is not None and not df_hosp.empty and df_hosp['total'].iloc[0] is not None else 0
        
        # Total d√©c√®s depuis la table de faits
        df_deces = execute_query(f"""
            SELECT SUM(f.nombre_deces) as total 
            FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
            JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
            {f"LEFT JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu" if region_filter else ""}
            WHERE f.type_evenement = 'DECES'
            AND t.date_complete >= ? AND t.date_complete <= ?
            {region_filter}
        """, [start_date, end_date] + region_param)
        total_deces = df_deces['total'].iloc[0] if df_deces is not None and not df_deces.empty and df_deces['total'].iloc[0] is not None else 0
        
        # Taux de satisfaction moyen depuis la table de faits
        # Note: Les donn√©es de satisfaction n'ont pas de date (id_temps = NULL)
        # et pas de code_lieu, donc pas de filtre par r√©gion
        # Donn√©es de 2017, donc on affiche toujours le score moyen global
        df_satisfaction = execute_query("""
            SELECT AVG(f.score_satisfaction) as score_moyen 
            FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
            WHERE f.type_evenement = 'SATISFACTION'
            AND f.score_satisfaction IS NOT NULL
        """, [])
        score_satisfaction = df_satisfaction['score_moyen'].iloc[0] if df_satisfaction is not None and not df_satisfaction.empty and df_satisfaction['score_moyen'].iloc[0] is not None else None
        
        # Nombre d'√©tablissements depuis la dimension
        df_etab = execute_query("SELECT COUNT(*) as total FROM warehouse.hypercube.DIM_ETABLISSEMENT")
        total_etab = df_etab['total'].iloc[0] if df_etab is not None and not df_etab.empty and df_etab['total'].iloc[0] is not None else 0
        
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es: {e}")
        total_hosp = total_deces = total_etab = 0
        score_satisfaction = None
    
    with col1:
        st.metric(
            label="Total Hospitalisations (filtr√© par date)",
            value=f"{total_hosp:,}" if total_hosp is not None else "0",
            delta="Donn√©es r√©elles"
        )
    
    with col2:
        st.metric(
            label="Total D√©c√®s (filtr√© par date)",
            value=f"{total_deces:,}" if total_deces is not None else "0",
            delta="Donn√©es r√©elles"
        )
    
    with col3:
        # Afficher satisfaction si disponible
        if score_satisfaction is not None and score_satisfaction > 0:
            st.metric(
                label="Taux de Satisfaction Globale (non filtr√©)",
                value=f"{score_satisfaction:.1f}/100",
                delta="Donn√©es 2017"
            )
        else:
            st.metric(
                label="Taux de Satisfaction Globale (non filtr√©)",
                value="N/A",
                delta="Disponible"
            )
    
    with col4:
        st.metric(
            label="√âtablissements Actifs (filtr√© par date)",
            value=f"{total_etab:,}" if total_etab is not None else "0",
            delta="Donn√©es r√©elles"
        )
    
    # Graphique d'√©volution temporelle
    st.markdown("---")
    st.subheader("üìä √âvolution des Hospitalisations (filtr√© par date)")
    
    try:
        # R√©cup√©rer les donn√©es filtr√©es par date
        query_evo = f"""
            SELECT 
                t.date_complete as Date,
                SUM(f.nombre_hospitalisation) as hospitalisations
            FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
            JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
            {f"LEFT JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu" if region_filter else ""}
            WHERE f.type_evenement = 'HOSPITALISATION'
            AND t.date_complete >= ? AND t.date_complete <= ?
            {region_filter}
            GROUP BY t.date_complete
            ORDER BY t.date_complete
        """
        
        df_evo = execute_query(query_evo, [start_date, end_date] + region_param)
        
        if df_evo is not None and not df_evo.empty:
            fig = px.line(df_evo, x='Date', y='hospitalisations', 
                         title='Evolution temporelle (filtr√© par date et r√©gion)',
                         labels={'hospitalisations': 'Nombre d\'hospitalisations', 'Date': 'Date'},
                         color_discrete_sequence=['#2196f3'])
            fig.update_traces(mode='lines+markers', line=dict(width=2))
            fig.update_layout(
                xaxis_title='Date',
                yaxis_title='Nombre d\'hospitalisations',
                hovermode='x unified'
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Aucune donn√©e d'√©volution disponible")
    except Exception as e:
        st.warning(f"Erreur lors du chargement: {e}")

def show_hospitalizations(start_date, end_date, region):
    """Analyse des hospitalisations"""
    st.header("üè• Hospitalisations")
    st.markdown("**Besoins : Taux global d'hospitalisation + par diagnostic + par sexe et √¢ge**")
    
    # Filtre par r√©gion
    if region == "Toutes":
        region_filter = ""
        region_param = []
    else:
        depts = [dept for dept, reg in CODE_POSTAL_TO_REGION.items() if reg == region]
        if depts:
            conditions = " OR ".join([f"SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) = '{dept}'" for dept in depts])
            region_filter = f"AND ({conditions})"
        else:
            region_filter = ""
        region_param = []
    
    # Taux global d'hospitalisation
    try:
        query_hosp_global = f"""
                SELECT 
                    SUM(f.nombre_hospitalisation) as total_hospitalisations,
                    AVG(f.duree_hospitalisation_jours) as duree_moyenne,
                    COUNT(DISTINCT f.id_patient) as patients_uniques
                FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
                JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
                {f"LEFT JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu" if region_filter else ""}
                WHERE f.type_evenement = 'HOSPITALISATION'
                AND t.date_complete >= ? AND t.date_complete <= ?
                {region_filter}
        """
        df_hosp_global = execute_query(query_hosp_global, [start_date, end_date] + region_param)
        
        if df_hosp_global is not None and not df_hosp_global.empty:
            total = df_hosp_global['total_hospitalisations'].iloc[0] if df_hosp_global['total_hospitalisations'].iloc[0] is not None else 0
            duree_moy = df_hosp_global['duree_moyenne'].iloc[0] if df_hosp_global['duree_moyenne'].iloc[0] is not None else 0
            patients = df_hosp_global['patients_uniques'].iloc[0] if df_hosp_global['patients_uniques'].iloc[0] is not None else 0
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total Hospitalisations", f"{total:,}")
            with col2:
                st.metric("Dur√©e moyenne", f"{duree_moy:.1f} jours")
            with col3:
                st.metric("Patients uniques", f"{patients:,}")
        else:
            st.warning("Aucune donn√©e d'hospitalisation disponible")
            return
            
    except Exception as e:
        st.error(f"Erreur: {e}")
        return
    
    # Graphiques d'analyse avec vraies donn√©es
    st.subheader("üìä Analyses d√©mographiques")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üë• Hospitalisations par sexe")
        # Vraies donn√©es depuis la base
        try:
            query_sexe = f"""
                SELECT 
                    p.sexe,
                    SUM(f.nombre_hospitalisation) as total_hospitalisations
                FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
                JOIN warehouse.hypercube.DIM_PATIENT p ON f.id_patient = p.id_patient
                JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
                {f"LEFT JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu" if region_filter else ""}
                WHERE f.type_evenement = 'HOSPITALISATION'
                AND t.date_complete >= ? AND t.date_complete <= ?
                {region_filter}
                GROUP BY p.sexe
                ORDER BY total_hospitalisations DESC
            """
            df_sexe = execute_query(query_sexe, [start_date, end_date] + region_param)
            
            if df_sexe is not None and not df_sexe.empty:
                # Graphique pie chart avec donut √©l√©gant
                fig_pie = px.pie(df_sexe, values='total_hospitalisations', names='sexe', 
                                title='Proportion par sexe',
                                color_discrete_sequence=['#3498db', '#e74c3c'],
                                hole=0.4)
                fig_pie.update_traces(textposition='inside', textinfo='percent+label+value')
                st.plotly_chart(fig_pie, use_container_width=True)
            else:
                st.info("Aucune donn√©e disponible")
        except Exception as e:
            st.warning(f"Erreur: {e}")
    
    with col2:
        st.markdown("### üìÖ Hospitalisations par √¢ge")
        # Vraies donn√©es depuis la base
        try:
            query_age = f"""
                SELECT 
                    CASE 
                        WHEN p.age < 18 THEN '0-17'
                        WHEN p.age BETWEEN 18 AND 35 THEN '18-35'
                        WHEN p.age BETWEEN 36 AND 50 THEN '36-50'
                        WHEN p.age BETWEEN 51 AND 65 THEN '51-65'
                        ELSE '65+'
                    END as tranche_age,
                    SUM(f.nombre_hospitalisation) as total_hospitalisations
                FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
                JOIN warehouse.hypercube.DIM_PATIENT p ON f.id_patient = p.id_patient
                JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
                {f"LEFT JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu" if region_filter else ""}
                WHERE f.type_evenement = 'HOSPITALISATION'
                AND t.date_complete >= ? AND t.date_complete <= ?
                {region_filter}
                GROUP BY tranche_age
                ORDER BY 
                    CASE tranche_age
                        WHEN '0-17' THEN 1
                        WHEN '18-35' THEN 2
                        WHEN '36-50' THEN 3
                        WHEN '51-65' THEN 4
                        ELSE 5
                    END
            """
            df_age = execute_query(query_age, [start_date, end_date] + region_param)
            
            if df_age is not None and not df_age.empty:
                # Graphique par √¢ge avec d√©grad√© de couleur
                fig = px.bar(df_age, x='tranche_age', y='total_hospitalisations', 
                           title='R√©partition par √¢ge',
                           color='total_hospitalisations',
                           color_continuous_scale='Reds',
                           text='total_hospitalisations',
                           labels={'tranche_age': 'Tranche d\'√¢ge', 'total_hospitalisations': 'Hospitalisations'})
                fig.update_traces(texttemplate='%{text}', textposition='outside')
                fig.update_layout(xaxis_title='Tranche d\'√¢ge', yaxis_title='Nombre d\'hospitalisations')
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("Aucune donn√©e disponible")
        except Exception as e:
            st.warning(f"Erreur: {e}")
    
    # Hospitalisations par cat√©gorie de diagnostic
    st.subheader("ü©∫ Hospitalisations par cat√©gorie de diagnostic")
    try:
        query_diag = f"""
            SELECT 
                d.categorie_diagnostic,
                SUM(f.nombre_hospitalisation) as total_hospitalisations,
                COUNT(DISTINCT f.id_patient) as patients_uniques
            FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
            JOIN warehouse.hypercube.DIM_DIAGNOSTIC d ON f.code_diag = d.code_diag
            JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
            {f"LEFT JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu" if region_filter else ""}
            WHERE f.type_evenement = 'HOSPITALISATION'
            AND t.date_complete >= ? AND t.date_complete <= ?
            {region_filter}
            GROUP BY d.categorie_diagnostic
            HAVING SUM(f.nombre_hospitalisation) > 0
            ORDER BY total_hospitalisations DESC
            LIMIT 20
        """
        df_diag = execute_query(query_diag, [start_date, end_date] + region_param)
        
        if df_diag is not None and not df_diag.empty:
            fig = px.bar(df_diag, x='total_hospitalisations', y='categorie_diagnostic',
                       orientation='h',
                       title='Top cat√©gories de diagnostics pour hospitalisations',
                       color='total_hospitalisations',
                       color_continuous_scale='Blues',
                       labels={'total_hospitalisations': 'Nombre d\'hospitalisations', 'categorie_diagnostic': 'Cat√©gorie de diagnostic'})
            fig.update_layout(yaxis={'categoryorder':'total ascending'})
            st.plotly_chart(fig, use_container_width=True)
            
            # Afficher aussi un tableau
            st.dataframe(df_diag[['categorie_diagnostic', 'total_hospitalisations', 'patients_uniques']], 
                        use_container_width=True, hide_index=True)
        else:
            st.info("Aucune donn√©e disponible")
    except Exception as e:
        st.warning(f"Erreur: {e}")

def show_consultations(start_date, end_date, region):
    """Analyse des consultations"""
    st.header("üë• Consultations")
    
    # Introduction / Storytelling
    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("""
        **Analyse des consultations m√©dicales** pour la p√©riode s√©lectionn√©e.
        
        Cette section pr√©sente les consultations selon deux dimensions cl√©s :
        - üìä **Par diagnostic** : Les motifs de consultation les plus fr√©quents
        - üë®‚Äç‚öïÔ∏è **Par professionnel** : Les types de professionnels les plus consult√©s
        """)
    
    # Filtre par r√©gion
    if region == "Toutes":
        region_filter = ""
        region_param = []
    else:
        depts = [dept for dept, reg in CODE_POSTAL_TO_REGION.items() if reg == region]
        if depts:
            conditions = " OR ".join([f"SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) = '{dept}'" for dept in depts])
            region_filter = f"AND ({conditions})"
        else:
            region_filter = ""
        region_param = []
    
    try:
        # Consultations par cat√©gorie de diagnostic - Top 15 uniquement
        st.subheader("üìä Consultations par cat√©gorie de diagnostic")
        st.markdown("*Top 15 des cat√©gories de diagnostics les plus fr√©quentes*")
        
        query_consult_diag = f"""
                SELECT 
                    d.categorie_diagnostic,
                    SUM(f.nombre_consultation) as total_consultations,
                    COUNT(DISTINCT f.id_patient) as patients_uniques
                FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
                JOIN warehouse.hypercube.DIM_DIAGNOSTIC d ON f.code_diag = d.code_diag
                JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
                {f"LEFT JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu" if region_filter else ""}
                WHERE f.type_evenement = 'CONSULTATION'
                AND t.date_complete >= ? AND t.date_complete <= ?
                {region_filter}
                GROUP BY d.categorie_diagnostic
                ORDER BY total_consultations DESC
                LIMIT 15
        """
        df_diag = execute_query(query_consult_diag, [start_date, end_date] + region_param)
        
        if df_diag is not None and not df_diag.empty:
            # Graphique horizontal pour meilleure lisibilit√©
            fig = px.bar(df_diag, x='total_consultations', y='categorie_diagnostic',
                        orientation='h',
                        title='Top 15 des cat√©gories de diagnostics',
                        color='total_consultations',
                        color_continuous_scale='Blues',
                        labels={'total_consultations': 'Nombre de consultations', 'categorie_diagnostic': 'Cat√©gorie de diagnostic'})
            fig.update_layout(yaxis={'categoryorder':'total ascending'}, 
                            height=600)
            # Tronquer les labels longs
            fig.update_yaxes(tickmode='linear')
            fig.update_layout(yaxis_automargin=True)
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau limit√© aux 10 premiers
            st.markdown("**D√©tail (Top 10)**")
            st.dataframe(df_diag.head(10), use_container_width=True, hide_index=True)
        else:
            st.info("Aucune donn√©e de consultation par diagnostic disponible")
            
    except Exception as e:
        st.warning(f"Erreur: {e}")
    
    # S√©parateur
    st.markdown("---")
    
    try:
        # Consultations par professionnel - Utilisation directe du lakehouse pour plus de m√©tiers
        st.subheader("üë®‚Äç‚öïÔ∏è Consultations par professionnel")
        st.markdown("*Toutes les professions consult√©es (requ√™te directe sur le lakehouse)*")
        
        # Utiliser la requ√™te directe sur le lakehouse pour obtenir plus de m√©tiers
        query_consult_prof = """
                SELECT 
                    s.Specialite as profession,
                    count(*) as total_consultations,
                    count(distinct c.Id_patient) as patients_uniques
                FROM 
                    lakehouse.main.consultation c
                LEFT JOIN lakehouse.main.professionnel_de_sante p 
                    ON c.Id_prof_sante = p.Identifiant
                LEFT JOIN lakehouse.main.specialites s
                    ON p.Code_specialite = s.Code_specialite
                WHERE s.Specialite IS NOT NULL
                GROUP BY s.Specialite
                ORDER BY total_consultations DESC
        """
        df_prof = execute_query(query_consult_prof, [])
        
        if df_prof is not None and not df_prof.empty:
            # Limiter √† 30 pour le graphique (plus que les 15 pr√©c√©dents pour voir plus de m√©tiers)
            df_prof_display = df_prof.head(30)
            
            # Graphique horizontal pour meilleure lisibilit√©
            fig = px.bar(df_prof_display, x='total_consultations', y='profession',
                        orientation='h',
                        title=f'Top {len(df_prof_display)} des professions ({len(df_prof)} au total)',
                        color='total_consultations',
                        color_continuous_scale='Greens',
                        labels={'total_consultations': 'Nombre de consultations', 'profession': 'Profession'})
            fig.update_layout(yaxis={'categoryorder':'total ascending'},
                            height=max(600, len(df_prof_display) * 20))
            fig.update_layout(yaxis_automargin=True)
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau avec tous les r√©sultats ou limit√© si trop nombreux
            st.markdown(f"**üìã D√©tail complet ({len(df_prof)} professions au total)**")
            if len(df_prof) > 50:
                st.info(f"Affichage des 50 premi√®res professions sur {len(df_prof)} au total")
                st.dataframe(df_prof.head(50), use_container_width=True, hide_index=True)
            else:
                st.dataframe(df_prof, use_container_width=True, hide_index=True)
        else:
            st.info("Aucune donn√©e de consultation par professionnel disponible")
            
    except Exception as e:
        st.warning(f"Erreur: {e}")

def show_deaths(start_date, end_date, region):
    """Analyse des d√©c√®s - Besoin : Nombre de d√©c√®s par localisation (r√©gion) sur l'ann√©e 2019"""
    st.header("üïäÔ∏è D√©c√®s")
    st.markdown("**Nombre de d√©c√®s par localisation (r√©gion) sur l'ann√©e 2019**")
    
    # Forcer l'ann√©e 2019 comme demand√© dans les besoins
    start_date = datetime(2019, 1, 1).date()
    end_date = datetime(2019, 12, 31).date()
    
    st.info(f"üìÖ P√©riode analys√©e : {start_date} √† {end_date}")
    
    # Carte de France avec les d√©c√®s par r√©gion
    st.subheader("üó∫Ô∏è Carte de France - D√©c√®s par r√©gion (2019)")
    
    try:
        # Requ√™te pour les d√©c√®s par r√©gion depuis la table de faits
        # On utilise SUBSTRING pour extraire le d√©partement du code_lieu
        query_deces_region = """
            SELECT 
                CASE 
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('75','77','78','91','92','93','94','95') THEN '√éle-de-France'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('01','03','07','15','26','38','42','43','63','69','73','74') THEN 'Auvergne-Rh√¥ne-Alpes'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('09','11','12','30','31','32','34','46','48','65','66','81','82') THEN 'Occitanie'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('16','17','19','23','24','33','40','47','64','79','86','87') THEN 'Nouvelle-Aquitaine'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('02','59','60','62','80') THEN 'Hauts-de-France'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('04','05','06','13','83','84') THEN 'Provence-Alpes-C√¥te d''Azur'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('08','10','51','52','54','55','57','67','68','88') THEN 'Grand Est'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('14','27','50','61','76') THEN 'Normandie'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('44','49','53','72','85') THEN 'Pays de la Loire'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('22','29','35','56') THEN 'Bretagne'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('18','28','36','37','41','45') THEN 'Centre-Val de Loire'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) IN ('21','25','39','58','70','71','89','90') THEN 'Bourgogne-Franche-Comt√©'
                    WHEN SUBSTRING(CAST(l.code_lieu AS VARCHAR), 1, 2) = '20' THEN 'Corse'
                    ELSE NULL
                END as region,
                SUM(f.nombre_deces) as nombre_deces
            FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
            JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu
            JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
            WHERE f.type_evenement = 'DECES' 
            AND t.date_complete >= ? AND t.date_complete <= ?
            AND l.code_lieu IS NOT NULL
            GROUP BY region
            HAVING region IS NOT NULL
            ORDER BY nombre_deces DESC
        """
        df_deces_region = execute_query(query_deces_region, [start_date, end_date])
        
        if df_deces_region is not None and not df_deces_region.empty:
            # Charger le GeoJSON des r√©gions
            geojson = get_regions_geojson()
            
            if geojson is not None:
                # Cr√©er une carte centr√©e sur la France
                m = folium.Map(location=[46.6034, 1.8883], zoom_start=6, tiles='OpenStreetMap')
                
                # Cr√©er un dictionnaire pour faciliter la recherche
                deaths_dict = dict(zip(df_deces_region['region'], df_deces_region['nombre_deces']))
                
                # Cr√©er une fonction pour mapper les valeurs aux couleurs
                max_deaths = df_deces_region['nombre_deces'].max()
                min_deaths = df_deces_region['nombre_deces'].min()
                
                def get_color(value, max_val, min_val):
                    """Retourne une couleur en fonction de la valeur"""
                    if max_val == min_val:
                        return '#ffcccc'
                    # Normaliser la valeur entre 0 et 1
                    normalized = (value - min_val) / (max_val - min_val)
                    # Utiliser une palette de rouge clair √† rouge fonc√©
                    if normalized < 0.2:
                        return '#ffcccc'
                    elif normalized < 0.4:
                        return '#ff9999'
                    elif normalized < 0.6:
                        return '#ff6666'
                    elif normalized < 0.8:
                        return '#ff3333'
                    else:
                        return '#cc0000'
                
                # Ajouter les r√©gions √† la carte
                for feature in geojson['features']:
                    # Essayer diff√©rents formats de noms de r√©gions dans le GeoJSON
                    properties = feature['properties']
                    region_name = (
                        properties.get('nom') or 
                        properties.get('name') or 
                        properties.get('nom_maj') or 
                        properties.get('NAME') or 
                        ''
                    )
                    
                    # Mapper le nom si n√©cessaire
                    region_name_mapped = map_region_name_to_geojson(region_name)
                    
                    # Chercher dans les donn√©es (essayer d'abord le nom original, puis le nom mapp√©)
                    nombre_deces = deaths_dict.get(region_name, deaths_dict.get(region_name_mapped, 0))
                    
                    # Couleur selon le nombre de d√©c√®s
                    fill_color = get_color(nombre_deces, max_deaths, min_deaths) if nombre_deces > 0 else '#f0f0f0'
                    
                    # Cr√©er une fonction de style pour cette r√©gion sp√©cifique
                    def make_style_function(color):
                        return lambda feat: {
                            'fillColor': color,
                            'color': 'black',
                            'weight': 1.5,
                            'fillOpacity': 0.7,
                        }
                    
                    # Utiliser le nom mapp√© pour l'affichage si disponible, sinon le nom original
                    display_name = region_name_mapped if region_name_mapped != region_name else region_name
                    
                    # Ajouter le style et les popups
                    folium.GeoJson(
                        feature,
                        style_function=make_style_function(fill_color),
                        tooltip=folium.Tooltip(
                            f"<b>{display_name}</b><br>Nombre de d√©c√®s: {nombre_deces:,}",
                            sticky=True
                        )
                    ).add_to(m)
                
                # Afficher la carte
                st_folium(m, width=700, height=500)
                
                # L√©gende
                st.caption("üé® **L√©gende** : Plus la r√©gion est fonc√©e, plus le nombre de d√©c√®s est √©lev√©")
                
                # Tableau r√©capitulatif
                st.markdown("**üìä Tableau r√©capitulatif par r√©gion**")
                st.dataframe(df_deces_region.sort_values('nombre_deces', ascending=False), 
                           use_container_width=True, hide_index=True)
            else:
                st.warning("Impossible de charger le GeoJSON des r√©gions. Affichage du tableau uniquement.")
                st.dataframe(df_deces_region.sort_values('nombre_deces', ascending=False), 
                           use_container_width=True, hide_index=True)
        else:
            st.warning("Aucune donn√©e de d√©c√®s par r√©gion disponible pour 2019")
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es de d√©c√®s par r√©gion: {e}")
    
    # Graphiques par commune (section existante)
    st.markdown("---")
    st.subheader("üìä Nombre de d√©c√®s par commune")
    
    # R√©cup√©rer les vraies donn√©es depuis l'entrep√¥t OLAP
    try:
        # Requ√™te pour les d√©c√®s par commune depuis la table de faits
        query_deces = """
            SELECT 
                l.commune,
                SUM(f.nombre_deces) as nombre_deces
            FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
            JOIN warehouse.hypercube.DIM_LOCALISATION l ON f.code_lieu = l.code_lieu
            JOIN warehouse.hypercube.DIM_TEMPS t ON f.id_temps = t.id_temps
            WHERE f.type_evenement = 'DECES' 
            AND t.date_complete >= ? AND t.date_complete <= ?
            GROUP BY l.commune
            ORDER BY nombre_deces DESC
            LIMIT 20
        """
        df_deces = execute_query(query_deces, [start_date, end_date])
        
        if df_deces is None or df_deces.empty:
            st.warning("Aucune donn√©e de d√©c√®s disponible pour 2019")
            return
            
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es de d√©c√®s: {e}")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.bar(df_deces, x='commune', y='nombre_deces', 
                    title='D√©c√®s par commune (2019)')
        fig.update_xaxes(tickangle=45)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        fig = px.pie(df_deces, values='nombre_deces', names='commune',
                    title='R√©partition des d√©c√®s par commune')
        st.plotly_chart(fig, use_container_width=True)
    
    # Tableau d√©taill√©
    st.subheader("üìã D√©tail par commune")
    st.dataframe(df_deces, use_container_width=True)

def show_satisfaction(start_date, end_date, region):
    """Analyse de la satisfaction globale - Donn√©es de 2017 (sans date dans la base)"""
    st.header("üòä Satisfaction Globale")
    st.markdown("**Taux global de satisfaction**")
    
    st.info("üìÖ Donn√©es de 2017 (p√©riode non disponible dans les donn√©es sources)")
    
    # R√©cup√©rer les vraies donn√©es de satisfaction depuis l'entrep√¥t OLAP
    try:
        query_satisfaction = """
            SELECT 
                COUNT(*) as nombre_reponses,
                ROUND(AVG(f.score_satisfaction), 2) as score_moyen,
                ROUND(MIN(f.score_satisfaction), 2) as score_min,
                ROUND(MAX(f.score_satisfaction), 2) as score_max,
                ROUND(STDDEV(f.score_satisfaction), 2) as score_ecart_type
            FROM warehouse.hypercube.FAIT_EVENEMENT_SANTE f
            WHERE f.type_evenement = 'SATISFACTION' 
            AND f.score_satisfaction IS NOT NULL
        """
        df_satisfaction = execute_query(query_satisfaction, [])
        
        if df_satisfaction is None or df_satisfaction.empty:
            st.warning("Aucune donn√©e de satisfaction disponible")
            return
        
        # Afficher les m√©triques globales
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Nombre de r√©ponses", f"{df_satisfaction['nombre_reponses'].iloc[0]:,}")
        with col2:
            st.metric("Score moyen", f"{df_satisfaction['score_moyen'].iloc[0]}/100")
        with col3:
            st.metric("Score min", f"{df_satisfaction['score_min'].iloc[0]}")
        with col4:
            st.metric("Score max", f"{df_satisfaction['score_max'].iloc[0]}")
        
        st.info("‚ÑπÔ∏è Les donn√©es de satisfaction ne contiennent pas d'information de localisation ni de date dans la base de donn√©es.")
        
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es de satisfaction: {e}")

if __name__ == "__main__":
    main()